{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Generate_Residuum.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "0XfaIegLC5hO",
        "rb0Sb_WWC9Gq",
        "NaYZpn7JjSGZ",
        "gCo8DfdgDJx0"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Inicjalizacja"
      ],
      "metadata": {
        "id": "0XfaIegLC5hO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inicjalizacja zmiennych"
      ],
      "metadata": {
        "id": "m_ft6RNkC8k0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfrecord_path_train_mal = 'drive/My Drive/Data/im_mal_dataset_train.tfrecords'\n",
        "tfrecord_path_test_mal = 'drive/My Drive/Data/im_mal_dataset_test.tfrecords'\n",
        "\n",
        "tfrecord_path_train_ben = 'drive/My Drive/Data/im_ben_dataset_train.tfrecords'\n",
        "tfrecord_path_test_ben = 'drive/My Drive/Data/im_ben_dataset_test.tfrecords'\n",
        "\n",
        "model_mal_8_path = 'drive/My Drive/Data/model_mal_8.h5'\n",
        "model_mal_16_path = 'drive/My Drive/Data/model_mal_16.h5'\n",
        "model_mal_32_path = 'drive/My Drive/Data/model_mal_32.h5'\n",
        "\n",
        "model_ben_8_path = 'drive/My Drive/Data/model_ben_8.h5'\n",
        "model_ben_16_path = 'drive/My Drive/Data/model_ben_16.h5'\n",
        "model_ben_32_path = 'drive/My Drive/Data/model_ben_32.h5'\n",
        "\n",
        "pickle_path_stats_train_mal_8_mal = 'drive/My Drive/Data/stats_train_mal_8_mal.pickle'\n",
        "pickle_path_stats_train_mal_16_mal = 'drive/My Drive/Data/stats_train_mal_16_mal.pickle'\n",
        "pickle_path_stats_train_mal_32_mal = 'drive/My Drive/Data/stats_train_mal_32_mal.pickle'\n",
        "pickle_path_stats_test_mal_8_mal = 'drive/My Drive/Data/stats_test_mal_8_mal.pickle'\n",
        "pickle_path_stats_test_mal_16_mal = 'drive/My Drive/Data/stats_test_mal_16_mal.pickle'\n",
        "pickle_path_stats_test_mal_32_mal = 'drive/My Drive/Data/stats_test_mal_32_mal.pickle'\n",
        "\n",
        "pickle_path_stats_train_mal_8_ben = 'drive/My Drive/Data/stats_train_mal_8_ben.pickle'\n",
        "pickle_path_stats_train_mal_16_ben = 'drive/My Drive/Data/stats_train_mal_16_ben.pickle'\n",
        "pickle_path_stats_train_mal_32_ben = 'drive/My Drive/Data/stats_train_mal_32_ben.pickle'\n",
        "pickle_path_stats_test_mal_8_ben = 'drive/My Drive/Data/stats_test_mal_8_ben.pickle'\n",
        "pickle_path_stats_test_mal_16_ben = 'drive/My Drive/Data/stats_test_mal_16_ben.pickle'\n",
        "pickle_path_stats_test_mal_32_ben = 'drive/My Drive/Data/stats_test_mal_32_ben.pickle'\n",
        "\n",
        "pickle_path_stats_train_ben_8_mal = 'drive/My Drive/Data/stats_train_ben_8_mal.pickle'\n",
        "pickle_path_stats_train_ben_16_mal = 'drive/My Drive/Data/stats_train_ben_16_mal.pickle'\n",
        "pickle_path_stats_train_ben_32_mal = 'drive/My Drive/Data/stats_train_ben_32_mal.pickle'\n",
        "pickle_path_stats_test_ben_8_mal = 'drive/My Drive/Data/stats_test_ben_8_mal.pickle'\n",
        "pickle_path_stats_test_ben_16_mal = 'drive/My Drive/Data/stats_test_ben_16_mal.pickle'\n",
        "pickle_path_stats_test_ben_32_mal = 'drive/My Drive/Data/stats_test_ben_32_mal.pickle'\n",
        "\n",
        "pickle_path_stats_train_ben_8_ben = 'drive/My Drive/Data/stats_train_ben_8_ben.pickle'\n",
        "pickle_path_stats_train_ben_16_ben = 'drive/My Drive/Data/stats_train_ben_16_ben.pickle'\n",
        "pickle_path_stats_train_ben_32_ben = 'drive/My Drive/Data/stats_train_ben_32_ben.pickle'\n",
        "pickle_path_stats_test_ben_8_ben = 'drive/My Drive/Data/stats_test_ben_8_ben.pickle'\n",
        "pickle_path_stats_test_ben_16_ben = 'drive/My Drive/Data/stats_test_ben_16_ben.pickle'\n",
        "pickle_path_stats_test_ben_32_ben = 'drive/My Drive/Data/stats_test_ben_32_ben.pickle'\n",
        "\n",
        "generate_residuum_mal = True\n",
        "generate_residuum_ben = True\n",
        "\n",
        "batch_size = 10\n",
        "patch_size = 256\n",
        "num_channels_input = 3\n",
        "num_channels_target = 3"
      ],
      "metadata": {
        "id": "MoHN8kIkDIX9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inicjalizacja bibliotek"
      ],
      "metadata": {
        "id": "ylcDInlZC8zh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import numpy as np\n",
        "from keras import layers\n",
        "import scipy\n",
        "import pickle\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMqOxjvADIsn",
        "outputId": "b6e2dce5-ea89-4823-94f8-b292b329ab92"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Funkcje"
      ],
      "metadata": {
        "id": "rb0Sb_WWC9Gq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_example_function(example_proto, image_feature_description):\n",
        "  # Parse the input tf.Example proto using the dictionary above.\n",
        "  return tf.io.parse_single_example(example_proto, image_feature_description)\n",
        "\n",
        "def img_img_parse_feature_function(img_features, patch_size, num_channels_input, num_channels_target):\n",
        "    input_tensor = tf.io.parse_tensor(img_features['input_image_raw'], out_type=tf.float32)\n",
        "    target_tensor = tf.io.parse_tensor(img_features['target_image_raw'], out_type=tf.float32)   \n",
        "    input_tensor.set_shape([patch_size, patch_size, num_channels_input])\n",
        "    target_tensor.set_shape([patch_size, patch_size, num_channels_target])\n",
        "    return input_tensor, target_tensor\n",
        "\n",
        "def tfrecord_2_img_img_dataset(tfrecord_path, batch_size, patch_size, num_channels_input=3, num_channels_target=1, num_prefatch=1, num_repeats=1):\n",
        "    \n",
        "    image_feature_description = {\n",
        "        'input_image_raw': tf.io.FixedLenFeature([], tf.string),\n",
        "        'target_image_raw': tf.io.FixedLenFeature([], tf.string)\n",
        "    }\n",
        "    \n",
        "    _parse_example = lambda example: parse_example_function(example, image_feature_description)\n",
        "    _parse_feature = lambda feature: img_img_parse_feature_function(feature, patch_size, num_channels_input, num_channels_target)\n",
        "\n",
        "    dataset = tf.data.TFRecordDataset(tfrecord_path)\n",
        "    dataset = dataset.map(_parse_example)\n",
        "    dataset = dataset.map(_parse_feature)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.prefetch(num_prefatch)\n",
        "    dataset = dataset.repeat(num_repeats)\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "faQfW4a5DJJo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_residuum(dset, model):\n",
        "  output = []\n",
        "\n",
        "  for elem_in, _ in dset:\n",
        "    decoded_imgs = model.predict(elem_in)\n",
        "    output.extend(decoded_imgs - elem_in.numpy())\n",
        "    \n",
        "  residuum = np.array(output)\n",
        "\n",
        "  return residuum\n",
        "\n",
        "def get_stats(array):\n",
        "  flatten_array = array.flatten()\n",
        "\n",
        "  s_max = max(flatten_array)\n",
        "  s_min = min(flatten_array)\n",
        "  s_energy = sum(flatten_array)\n",
        "  s_10p = np.percentile(flatten_array,10)\n",
        "  s_90p = np.percentile(flatten_array,90)\n",
        "\n",
        "  s_median = np.median(flatten_array)\n",
        "  s_mean = np.mean(flatten_array)\n",
        "  s_range = np.ptp(flatten_array)\n",
        "  s_var = np.var(flatten_array)\n",
        "  s_iqr = scipy.stats.iqr(flatten_array)\n",
        "\n",
        "  s_skew = scipy.stats.skew(flatten_array)\n",
        "  s_kurtosis = scipy.stats.kurtosis(flatten_array)\n",
        "  s_medabsdev = scipy.stats.median_absolute_deviation(flatten_array)\n",
        "  s_meanabsdev = np.mean(np.absolute(flatten_array - np.mean(flatten_array)))\n",
        "  #s_entropy = scipy.stats.entropy(flatten_array)\n",
        "\n",
        "  stats = np.array([s_max, s_min, s_energy, s_10p, s_90p,\n",
        "                    s_median, s_mean, s_range, s_var, s_iqr,\n",
        "                    s_skew, s_kurtosis, s_medabsdev, s_meanabsdev])\n",
        "  \n",
        "  return stats\n",
        "\n",
        "def get_stats_rgb(array):\n",
        "  stats = np.array([])\n",
        "  for i in range(0,3):\n",
        "    stats = np.append(stats, get_stats(array[:,:,i]))\n",
        "  \n",
        "  return stats\n",
        "\n",
        "def get_stats_all(dset, model):\n",
        "  resid = get_residuum(dset, model)\n",
        "  stats = []\n",
        " \n",
        "  for res in resid:\n",
        "    stats.append(get_stats_rgb(res))\n",
        "\n",
        "  return np.array(stats)"
      ],
      "metadata": {
        "id": "aHLXbYHsiTig"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ≈Åadowanie danych"
      ],
      "metadata": {
        "id": "NaYZpn7JjSGZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ≈Åadowanie modeli"
      ],
      "metadata": {
        "id": "EUkbGqdljU7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder_model_mal_8 = keras.models.load_model(model_mal_8_path)\n",
        "autoencoder_model_mal_16 = keras.models.load_model(model_mal_16_path)\n",
        "autoencoder_model_mal_32 = keras.models.load_model(model_mal_32_path)\n",
        "autoencoder_model_ben_8 = keras.models.load_model(model_ben_8_path)\n",
        "autoencoder_model_ben_16 = keras.models.load_model(model_ben_16_path)\n",
        "autoencoder_model_ben_32 = keras.models.load_model(model_ben_32_path)"
      ],
      "metadata": {
        "id": "JzdIBH-TjT2L"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ≈Åadowanie TFRecords"
      ],
      "metadata": {
        "id": "c9DdwxdVjXim"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dset_train_ben = tfrecord_2_img_img_dataset(tfrecord_path_train_ben, batch_size, patch_size, num_channels_input, num_channels_target, num_repeats = 1)\n",
        "dset_test_ben = tfrecord_2_img_img_dataset(tfrecord_path_test_ben, batch_size, patch_size, num_channels_input, num_channels_target, num_repeats = 1)\n",
        "\n",
        "dset_train_mal = tfrecord_2_img_img_dataset(tfrecord_path_train_mal, batch_size, patch_size, num_channels_input, num_channels_target, num_repeats = 1)\n",
        "dset_test_mal = tfrecord_2_img_img_dataset(tfrecord_path_test_mal, batch_size, patch_size, num_channels_input, num_channels_target, num_repeats = 1)"
      ],
      "metadata": {
        "id": "QjkBL5DrjUTQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generacja residuum"
      ],
      "metadata": {
        "id": "gCo8DfdgDJx0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Malignant"
      ],
      "metadata": {
        "id": "XWIdJYjHKQl4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if generate_residuum_mal:\n",
        "  stats_stats_train_mal_8_mal = get_stats_all(dset_train_mal, autoencoder_model_mal_8)\n",
        "\n",
        "  with open(pickle_path_stats_train_mal_8_mal, 'wb') as handle:\n",
        "    pickle.dump(stats_stats_train_mal_8_mal, handle)\n",
        "\n",
        "  stats_stats_train_mal_16_mal = get_stats_all(dset_train_mal, autoencoder_model_mal_16)\n",
        "\n",
        "  with open(pickle_path_stats_train_mal_16_mal, 'wb') as handle:\n",
        "    pickle.dump(stats_stats_train_mal_16_mal, handle)\n",
        "\n",
        "  stats_stats_train_mal_32_mal = get_stats_all(dset_train_mal, autoencoder_model_mal_32)\n",
        "\n",
        "  with open(pickle_path_stats_train_mal_32_mal, 'wb') as handle:\n",
        "    pickle.dump(stats_stats_train_mal_32_mal, handle)\n",
        "\n",
        "  stats_stats_test_mal_8_mal = get_stats_all(dset_test_mal, autoencoder_model_mal_8)\n",
        "\n",
        "  with open(pickle_path_stats_test_mal_8_mal, 'wb') as handle:\n",
        "    pickle.dump(stats_stats_test_mal_8_mal, handle)\n",
        "\n",
        "  stats_stats_test_mal_16_mal = get_stats_all(dset_test_mal, autoencoder_model_mal_16)\n",
        "\n",
        "  with open(pickle_path_stats_test_mal_16_mal, 'wb') as handle:\n",
        "    pickle.dump(stats_stats_test_mal_16_mal, handle)\n",
        "\n",
        "  stats_stats_test_mal_32_mal = get_stats_all(dset_test_mal, autoencoder_model_mal_32)\n",
        "\n",
        "  with open(pickle_path_stats_test_mal_32_mal, 'wb') as handle:\n",
        "    pickle.dump(stats_stats_test_mal_32_mal, handle)\n",
        "\n",
        "  ############################################################################\n",
        "\n",
        "  stats_stats_train_mal_8_ben = get_stats_all(dset_train_ben, autoencoder_model_mal_8)\n",
        "\n",
        "  with open(pickle_path_stats_train_mal_8_ben, 'wb') as handle:\n",
        "    pickle.dump(stats_stats_train_mal_8_ben, handle)\n",
        "\n",
        "  stats_stats_train_mal_16_ben = get_stats_all(dset_train_ben, autoencoder_model_mal_16)\n",
        "\n",
        "  with open(pickle_path_stats_train_mal_16_ben, 'wb') as handle:\n",
        "    pickle.dump(stats_stats_train_mal_16_ben, handle)\n",
        "\n",
        "  stats_stats_train_mal_32_ben = get_stats_all(dset_train_ben, autoencoder_model_mal_32)\n",
        "\n",
        "  with open(pickle_path_stats_train_mal_32_ben, 'wb') as handle:\n",
        "    pickle.dump(stats_stats_train_mal_32_ben, handle)\n",
        "\n",
        "  stats_stats_test_mal_8_ben = get_stats_all(dset_test_ben, autoencoder_model_mal_8)\n",
        "\n",
        "  with open(pickle_path_stats_test_mal_8_ben, 'wb') as handle:\n",
        "    pickle.dump(stats_stats_test_mal_8_ben, handle)\n",
        "\n",
        "  stats_stats_test_mal_16_ben = get_stats_all(dset_test_ben, autoencoder_model_mal_16)\n",
        "\n",
        "  with open(pickle_path_stats_test_mal_16_ben, 'wb') as handle:\n",
        "    pickle.dump(stats_stats_test_mal_16_ben, handle)\n",
        "\n",
        "  stats_stats_test_mal_32_ben = get_stats_all(dset_test_ben, autoencoder_model_mal_32)\n",
        "\n",
        "  with open(pickle_path_stats_test_mal_32_ben, 'wb') as handle:\n",
        "    pickle.dump(stats_stats_test_mal_32_ben, handle)"
      ],
      "metadata": {
        "id": "KPlZSj-cvVSk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Benign"
      ],
      "metadata": {
        "id": "i6tcmT0yKQTF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if generate_residuum_ben:\n",
        "  stats_stats_train_ben_8_mal = get_stats_all(dset_train_mal, autoencoder_model_ben_8)\n",
        "\n",
        "  with open(pickle_path_stats_train_ben_8_mal, 'wb') as handle:\n",
        "    pickle.dump(stats_stats_train_ben_8_mal, handle)\n",
        "\n",
        "  stats_stats_train_ben_16_mal = get_stats_all(dset_train_mal, autoencoder_model_ben_16)\n",
        "\n",
        "  with open(pickle_path_stats_train_ben_16_mal, 'wb') as handle:\n",
        "    pickle.dump(stats_stats_train_ben_16_mal, handle)\n",
        "\n",
        "  stats_stats_train_ben_32_mal = get_stats_all(dset_train_mal, autoencoder_model_ben_32)\n",
        "\n",
        "  with open(pickle_path_stats_train_ben_32_mal, 'wb') as handle:\n",
        "    pickle.dump(stats_stats_train_ben_32_mal, handle)\n",
        "\n",
        "  stats_stats_test_ben_8_mal = get_stats_all(dset_test_mal, autoencoder_model_ben_8)\n",
        "\n",
        "  with open(pickle_path_stats_test_ben_8_mal, 'wb') as handle:\n",
        "    pickle.dump(stats_stats_test_ben_8_mal, handle)\n",
        "\n",
        "  stats_stats_test_ben_16_mal = get_stats_all(dset_test_mal, autoencoder_model_ben_16)\n",
        "\n",
        "  with open(pickle_path_stats_test_ben_16_mal, 'wb') as handle:\n",
        "    pickle.dump(stats_stats_test_ben_16_mal, handle)\n",
        "\n",
        "  stats_stats_test_ben_32_mal = get_stats_all(dset_test_mal, autoencoder_model_ben_32)\n",
        "\n",
        "  with open(pickle_path_stats_test_ben_32_mal, 'wb') as handle:\n",
        "    pickle.dump(stats_stats_test_ben_32_mal, handle)\n",
        "\n",
        "  ############################################################################\n",
        "\n",
        "  stats_stats_train_ben_8_ben = get_stats_all(dset_train_ben, autoencoder_model_ben_8)\n",
        "\n",
        "  with open(pickle_path_stats_train_ben_8_ben, 'wb') as handle:\n",
        "    pickle.dump(stats_stats_train_ben_8_ben, handle)\n",
        "\n",
        "  stats_stats_train_ben_16_ben = get_stats_all(dset_train_ben, autoencoder_model_ben_16)\n",
        "\n",
        "  with open(pickle_path_stats_train_ben_16_ben, 'wb') as handle:\n",
        "    pickle.dump(stats_stats_train_ben_16_ben, handle)\n",
        "\n",
        "  stats_stats_train_ben_32_ben = get_stats_all(dset_train_ben, autoencoder_model_ben_32)\n",
        "\n",
        "  with open(pickle_path_stats_train_ben_32_ben, 'wb') as handle:\n",
        "    pickle.dump(stats_stats_train_ben_32_ben, handle)\n",
        "\n",
        "  stats_stats_test_ben_8_ben = get_stats_all(dset_test_ben, autoencoder_model_ben_8)\n",
        "\n",
        "  with open(pickle_path_stats_test_ben_8_ben, 'wb') as handle:\n",
        "    pickle.dump(stats_stats_test_ben_8_ben, handle)\n",
        "\n",
        "  stats_stats_test_ben_16_ben = get_stats_all(dset_test_ben, autoencoder_model_ben_16)\n",
        "\n",
        "  with open(pickle_path_stats_test_ben_16_ben, 'wb') as handle:\n",
        "    pickle.dump(stats_stats_test_ben_16_ben, handle)\n",
        "\n",
        "  stats_stats_test_ben_32_ben = get_stats_all(dset_test_ben, autoencoder_model_ben_32)\n",
        "\n",
        "  with open(pickle_path_stats_test_ben_32_ben, 'wb') as handle:\n",
        "    pickle.dump(stats_stats_test_ben_32_ben, handle)"
      ],
      "metadata": {
        "id": "GCLulmtHzJ4f"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}