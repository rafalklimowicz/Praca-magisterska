{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Generate_TFRecords_Train_Test.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "M699t3GmdTVI",
        "6MYre3CjdZCD",
        "XkPEXUyzdbG_",
        "bOVCJWhpeipv"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Inicjalizacja"
      ],
      "metadata": {
        "id": "M699t3GmdTVI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inicjalizacja zmiennych"
      ],
      "metadata": {
        "id": "pTv63huvdW10"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "malignant_data = 'drive/My Drive/Data/Malignant/'\n",
        "benign_data = 'drive/My Drive/Data/Benign/'\n",
        "\n",
        "tfrecord_path_train_mal = 'drive/My Drive/Data/im_mal_dataset_train.tfrecords'\n",
        "tfrecord_path_test_mal = 'drive/My Drive/Data/im_mal_dataset_test.tfrecords'\n",
        "tfrecord_path_train_ben = 'drive/My Drive/Data/im_ben_dataset_train.tfrecords'\n",
        "tfrecord_path_test_ben = 'drive/My Drive/Data/im_ben_dataset_test.tfrecords'\n",
        "\n",
        "data_split = (0.7, 0.3, 0)\n",
        "char_irrel = 7\n",
        "num_patches_per_image = 10\n",
        "batch_size = 10\n",
        "patch_size = 256\n",
        "\n",
        "generate_malignant = True\n",
        "generate_benign = True"
      ],
      "metadata": {
        "id": "FTMj1QsVdfnd"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inicjalizacja bibliotek"
      ],
      "metadata": {
        "id": "6MYre3CjdZCD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall tensorflow\n",
        "!pip uninstall tensorflow-io\n",
        "!pip install tensorflow-gpu\n",
        "!pip install --no-deps tensorflow-io\n",
        "!pip install tensorflow_addons\n",
        "!pip install pyyaml h5py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOtnN1-Xf5jF",
        "outputId": "e8eda39a-2672-41d6-8df6-52d7ab65fca2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping tensorflow as it is not installed.\u001b[0m\n",
            "Found existing installation: tensorflow-io 0.26.0\n",
            "Uninstalling tensorflow-io-0.26.0:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow_io-0.26.0.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow_io/*\n",
            "Proceed (y/n)? n\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow-gpu in /usr/local/lib/python3.7/dist-packages (2.9.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.9.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.17.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.2.0)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.9.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.0.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (14.0.1)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.12)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.26.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.21.6)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.46.1)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (21.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (57.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.9.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (4.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.14.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow-gpu) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow-gpu) (1.5.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (3.3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (1.35.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-gpu) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-gpu) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-gpu) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow-gpu) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow-gpu) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow-gpu) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-gpu) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-gpu) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-gpu) (2022.5.18.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow-gpu) (3.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow-gpu) (3.0.9)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow-io in /usr/local/lib/python3.7/dist-packages (0.26.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow_addons in /usr/local/lib/python3.7/dist-packages (0.17.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow_addons) (3.0.9)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from h5py) (1.21.6)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py) (1.5.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import glob\n",
        "import tensorflow as tf\n",
        "import tensorflow_io as tfio\n",
        "import tensorflow_addons as tfa\n",
        "import os\n",
        "import random\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3k6bot-VdfKz",
        "outputId": "012a18ef-43e1-487c-e048-0d447c3eabd0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Funkcje"
      ],
      "metadata": {
        "id": "XkPEXUyzdbG_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "rrPwBz07dCuh"
      },
      "outputs": [],
      "source": [
        "############ Augmentations ######################################\n",
        "##################################\n",
        "def random_rotation_im_im(image, target):\n",
        "    \"\"\"Rotate augmentation\n",
        "    Args:\n",
        "        image: Input image\n",
        "        target: Target image\n",
        "    Returns:\n",
        "        Augmented image and augemented target image\n",
        "    \"\"\"\n",
        "    num_input_channels = tf.shape(image)[2]\n",
        "    num_target_channels = tf.shape(target)[2]\n",
        "    im_tar = tf.concat([image, target], axis=2)\n",
        "    angle = random.randint(1,359)\n",
        "    im_tar = tfa.image.rotate(im_tar, \n",
        "                             angle, \n",
        "                             interpolation='NEAREST', \n",
        "                             name=None)\n",
        "    image, target = tf.split(im_tar, num_or_size_splits=[num_input_channels, num_target_channels], axis=2)\n",
        "    return image, target\n",
        "\n",
        "##################################\n",
        "def flip_up_down_im_im(image, target):\n",
        "    \"\"\"Flip augmentation\n",
        "    Args:\n",
        "        image: Input image\n",
        "        target: Target image\n",
        "    Returns:\n",
        "        Augmented image and augemented target image\n",
        "    \"\"\"\n",
        "    num_input_channels = tf.shape(image)[2]\n",
        "    num_target_channels = tf.shape(target)[2]\n",
        "    im_tar = tf.concat([image, target], axis=2)\n",
        "    im_tar = tf.image.flip_up_down(im_tar)\n",
        "    image, target = tf.split(im_tar, num_or_size_splits=[num_input_channels, num_target_channels], axis=2)\n",
        "    return image, target\n",
        "\n",
        "##################################\n",
        "def flip_left_right_im_im(image, target):\n",
        "    \"\"\"Flip augmentation\n",
        "    Args:\n",
        "        image: Input image\n",
        "        target: Target image\n",
        "    Returns:\n",
        "        Augmented image and augemented target image\n",
        "    \"\"\"\n",
        "    num_input_channels = tf.shape(image)[2]\n",
        "    num_target_channels = tf.shape(target)[2]\n",
        "    im_tar = tf.concat([image, target], axis=2)\n",
        "    im_tar = tf.image.flip_left_right(im_tar)\n",
        "    image, target = tf.split(im_tar, num_or_size_splits=[num_input_channels, num_target_channels], axis=2)\n",
        "    return image, target\n",
        "\n",
        "\n",
        "#############################\n",
        "def rotate_im_im(image, target):\n",
        "    \"\"\"Rotation augmentation\n",
        "    Randomly chosen rotation angle:  0, 90, 180, 270 degrees\n",
        "    Args:\n",
        "        image: Input image\n",
        "        target: Target image\n",
        "    Returns:\n",
        "        Augmented image and augemented target image\n",
        "    \"\"\"\n",
        "    num_input_channels = tf.shape(image)[2]\n",
        "    num_target_channels = tf.shape(target)[2]\n",
        "    im_tar = tf.concat([image, target], axis=2) \n",
        "    im_tar = tf.image.rot90(im_tar, tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32))\n",
        "    image, target = tf.split(im_tar, num_or_size_splits=[num_input_channels, num_target_channels], axis=2)\n",
        "    return image, target\n",
        "\n",
        "\n",
        "#################################\n",
        "def random_rotation_im_lab(image, target):\n",
        "    \"\"\"Rotate augmentation\n",
        "    Args:\n",
        "        image: Image\n",
        "        target: Class label\n",
        "    Returns:\n",
        "        Augmented image and label\n",
        "    \"\"\"\n",
        "    angle = random.randint(1,359)\n",
        "    image = tfa.image.rotate(image, \n",
        "                          angle, \n",
        "                          interpolation='NEAREST', \n",
        "                          name=None)\n",
        "    return image, target\n",
        "\n",
        "##################################\n",
        "def flip_up_down_im_lab(image, target):\n",
        "    \"\"\"Flip augmentation\n",
        "    Args:\n",
        "        image: Image\n",
        "        target: Class label\n",
        "    Returns:\n",
        "        Augmented image and label\n",
        "    \"\"\"\n",
        "    image = tf.image.flip_up_down(image)\n",
        "    return image, target\n",
        "\n",
        "##################################\n",
        "def flip_left_right_im_lab(image, target):\n",
        "    \"\"\"Flip augmentation\n",
        "    Args:\n",
        "        image: Image\n",
        "        target: Class label\n",
        "    Returns:\n",
        "        Augmented image and label\n",
        "    \"\"\"\n",
        "    image = tf.image.flip_left_right(image)\n",
        "    return image, target\n",
        "\n",
        "\n",
        "#############################\n",
        "def rotate_im_lab(image, target):\n",
        "    \"\"\"Rotation augmentation\n",
        "    Randomly chosen rotation angle:  0, 90, 180, 270 degrees\n",
        "    Args:\n",
        "        image: Image\n",
        "        target: Class label\n",
        "    Returns:\n",
        "        Augmented image and label\n",
        "    \"\"\"\n",
        "    image = tf.image.rot90(image, tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32))\n",
        "    return image, target\n",
        "\n",
        "def image_image_feeder(path_base_input, \n",
        "                       path_base_target,\n",
        "                       filenames_input,\n",
        "                       filenames_target,\n",
        "                       from_disk=True,\n",
        "                       num_patches_per_image=6,\n",
        "                       patch_size = 128,\n",
        "                       shuffle_buffer_size_images=5,\n",
        "                       shuffle_buffer_size_patches=10,\n",
        "                       batch_size=6,\n",
        "                       intensity_thresh_input = 0.1,\n",
        "                       intensity_thresh_target = 0.1,\n",
        "                       accept_thresh_input = 0.5,\n",
        "                       accept_thresh_target = 0.5,\n",
        "                       invert_input=False,\n",
        "                       invert_target=False,\n",
        "                       max_tries = 10,\n",
        "                       p_augment=0.5,\n",
        "                       augmentations=[rotate_im_im, flip_up_down_im_im, flip_left_right_im_im],\n",
        "                       shuffle_images=True,\n",
        "                       shuffle_patches=True,\n",
        "                       standarize=True,\n",
        "                       num_prefetched_patches=1,\n",
        "                       num_parallel_calls=4):\n",
        "    \n",
        "    num_all_pixels =  patch_size *  patch_size;\n",
        "    file_paths_input = [os.path.join(path_base_input, fn) for fn in filenames_input]\n",
        "    file_paths_target = [os.path.join(path_base_target, fn) for fn in filenames_target]\n",
        "    \n",
        "    if from_disk:\n",
        "        dataset = tf.data.Dataset.from_tensor_slices((file_paths_input, file_paths_target))\n",
        "    else:\n",
        "        images = load_image_image_ram(file_paths_input, file_paths_target)\n",
        "        dataset = tf.data.Dataset.from_tensor_slices(images)\n",
        "    \n",
        "    if shuffle_images:\n",
        "        dataset = dataset.shuffle(buffer_size=shuffle_buffer_size_images)\n",
        "    \n",
        "    if from_disk:\n",
        "        dataset = dataset.map(load_paired_images)\n",
        "    \n",
        "    if standarize:\n",
        "        dataset = dataset.map(standarize_image_image, num_parallel_calls=num_parallel_calls)\n",
        "        \n",
        "    get_patches_fn_train = lambda image_input, image_target: get_patches_im_im(image_input, image_target, \n",
        "                                                                               num_all_pixels, \n",
        "                                                                               num_patches=num_patches_per_image, \n",
        "                                                                               patch_size=patch_size, \n",
        "                                                                               max_tries=max_tries,\n",
        "                                                                               input_pixel_threshold=intensity_thresh_input, \n",
        "                                                                               input_accept_threshold=accept_thresh_input,\n",
        "                                                                               input_invert=invert_input, \n",
        "                                                                               target_pixel_threshold=intensity_thresh_target, \n",
        "                                                                               target_accept_threshold=accept_thresh_target,\n",
        "                                                                               target_invert=invert_target)\n",
        "    dataset = dataset.map(get_patches_fn_train, num_parallel_calls=num_parallel_calls)\n",
        "    dataset = dataset.unbatch()\n",
        "    if len(augmentations) != 0:\n",
        "        for f in augmentations:\n",
        "            dataset = dataset.map(lambda x, y: tf.cond(tf.random.uniform([], 0, 1) > (1 - p_augment), lambda: f(x, y), lambda: (x, y)), \n",
        "                                              num_parallel_calls=num_parallel_calls)\n",
        "    if shuffle_patches:\n",
        "        dataset = dataset.shuffle(buffer_size=shuffle_buffer_size_patches)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.prefetch(num_prefetched_patches)\n",
        "    dataset = dataset.repeat()\n",
        "    return dataset\n",
        "\n",
        "def load_image_image_ram(input_paths, target_paths):\n",
        "    #Loading images into memory\n",
        "    print('Loading input and target images into RAM ...')\n",
        "    \n",
        "    imgs_input = None\n",
        "    imgs_target = None\n",
        "    \n",
        "    for filename_input, filename_target in zip(input_paths, target_paths):\n",
        "        img_input, img_target = load_paired_images(filename_input, filename_target)\n",
        "        \n",
        "        img_input = tf.expand_dims(img_input, axis=0)\n",
        "        img_target = tf.expand_dims(img_target, axis=0)\n",
        "        if imgs_input is None:\n",
        "            imgs_input = img_input\n",
        "        else:\n",
        "            imgs_input = tf.concat([imgs_input, img_input], axis=0)\n",
        "        if imgs_target is None:\n",
        "            imgs_target = img_target\n",
        "        else:\n",
        "            imgs_target = tf.concat([imgs_target, img_target], axis=0)\n",
        "    return imgs_input, imgs_target\n",
        "\n",
        "def load_paired_images(filename_input, filename_target):\n",
        "    image_string_input = tf.io.read_file(filename_input)\n",
        "    image_decoded_input = tfio.experimental.image.decode_tiff(image_string_input)\n",
        "    image_input = tf.image.convert_image_dtype(image_decoded_input, tf.float32)\n",
        "\n",
        "    image_string_target = tf.io.read_file(filename_target)\n",
        "    image_decoded_target = tfio.experimental.image.decode_tiff(image_string_target)\n",
        "    image_target = tf.image.convert_image_dtype(image_decoded_target, tf.float32)\n",
        "\n",
        "    return image_input[:,:,0:3], image_target[:,:,0:3]\n",
        "\n",
        "def standarize_image_image(image_input, image_target):\n",
        "    return tf.image.per_image_standardization(image_input), tf.image.per_image_standardization(image_target)\n",
        "\n",
        "def get_patches_im_im(image_input, image_target, \n",
        "                      num_all_pixels, \n",
        "                      num_patches=10, \n",
        "                      patch_size=32, \n",
        "                      max_tries=2, \n",
        "                      input_pixel_threshold=0, \n",
        "                      input_accept_threshold=0,\n",
        "                      input_invert=False, \n",
        "                      target_pixel_threshold=0, \n",
        "                      target_accept_threshold=0,\n",
        "                      target_invert=False):\n",
        " \n",
        "    epsilon = 0.000001\n",
        "    patches = []\n",
        "    input_invert = tf.constant(input_invert, dtype=tf.bool)\n",
        "    target_invert = tf.constant(target_invert, dtype=tf.bool)\n",
        "    num_input_channels = tf.shape(image_input)[2]\n",
        "    num_target_channels = tf.shape(image_target)[2]\n",
        "    num_concat_channels = num_input_channels + num_target_channels\n",
        "    \n",
        "    image_input_target_paired = tf.concat([image_input, image_target], axis=2)\n",
        "    for i in range(num_patches):\n",
        "        patch = tf.zeros([patch_size, patch_size, num_concat_channels], dtype=tf.float32)\n",
        "        \n",
        "        k = 1\n",
        "        while tf.constant(True, dtype=tf.bool):\n",
        "            #patch = tf.image.random_crop(image_input_target_paired, [patch_size, patch_size, num_concat_channels])\n",
        "            patch = tf.image.random_crop(image_input_target_paired, [patch_size, patch_size, tf.shape(image_input)[2]+tf.shape(image_target)[2]])\n",
        "            img_input = patch[:,:,0:num_input_channels]\n",
        "            if num_input_channels > 1:\n",
        "                img_input = tf.image.rgb_to_grayscale(img_input)\n",
        "            \n",
        "            #min_input = tf.math.reduce_min(img_input) \n",
        "            #max_input = tf.math.reduce_max(img_input) \n",
        "            #range_input = max_input - min_input\n",
        "            #img_input = (img_input - min_input + epsilon) / (range_input + 2*epsilon)\n",
        "            \n",
        "            img_target = patch[:,:,num_input_channels:num_concat_channels]\n",
        "            if num_target_channels > 1:\n",
        "                img_target = tf.image.rgb_to_grayscale(img_target)  \n",
        "            \n",
        "            #min_target = tf.math.reduce_min(img_target) \n",
        "            #max_target = tf.math.reduce_max(img_target) \n",
        "            #range_target = max_target - min_target\n",
        "            #img_target = (img_target - min_target + epsilon) / (range_target + 2*epsilon)\n",
        "            \n",
        "            img_input = tf.math.floor(img_input - input_pixel_threshold) + 1\n",
        "            img_input = tf.clip_by_value(img_input, clip_value_min=0, clip_value_max=1)\n",
        "            img_target = tf.math.floor(img_target - target_pixel_threshold) + 1\n",
        "            img_target  = tf.clip_by_value(img_target, clip_value_min=0, clip_value_max=1)\n",
        "            num_input_accepted_pixels = tf.math.reduce_sum(img_input)\n",
        "            num_target_accepted_pixels = tf.math.reduce_sum(img_target)\n",
        "            if (k >= max_tries):\n",
        "                break\n",
        "            if (((num_input_accepted_pixels/num_all_pixels) >= input_accept_threshold) and \n",
        "                ((num_target_accepted_pixels/num_all_pixels) >= target_accept_threshold)) and (~input_invert) and (~target_invert):\n",
        "                break\n",
        "\n",
        "            if ((((num_all_pixels - num_input_accepted_pixels)/num_all_pixels) >= input_accept_threshold) and \n",
        "                ((num_target_accepted_pixels/num_all_pixels) >= target_accept_threshold)) and (input_invert) and (~target_invert):\n",
        "                break\n",
        "\n",
        "            if ((((num_all_pixels - num_input_accepted_pixels)/num_all_pixels) >= input_accept_threshold) and \n",
        "                (((num_all_pixels - num_target_accepted_pixels)/num_all_pixels) >= target_accept_threshold)) and (input_invert) and (target_invert):\n",
        "                break\n",
        "\n",
        "            if (((num_input_accepted_pixels/num_all_pixels) >= input_accept_threshold) and \n",
        "                (((num_all_pixels - num_target_accepted_pixels)/num_all_pixels) >= target_accept_threshold)) and (~input_invert) and (target_invert):\n",
        "                break\n",
        "\n",
        "            k = k + 1                \n",
        "        patches.append(patch)\n",
        "    patches = tf.stack(patches)\n",
        "    patches_input, patches_target = tf.split(patches, num_or_size_splits=[num_input_channels, num_target_channels], axis=3)\n",
        "   \n",
        "    return patches_input, patches_target\n",
        "\n",
        "def img_img_dataset_2_tfrecord(dataset, tfrecord_path, num_batches_gen):\n",
        "    it_dataset = iter(dataset)\n",
        "    with tf.io.TFRecordWriter(tfrecord_path) as tfrecord_writer:\n",
        "        for k in range(num_batches_gen): \n",
        "            im_input, im_target = it_dataset.next()\n",
        "            img_img_store_batch_tfrecord(im_input, im_target, tfrecord_writer)\n",
        "\n",
        "def img_img_store_batch_tfrecord(img_input_batch, img_target_batch, writer):\n",
        "    num_samples = img_input_batch.shape[0]\n",
        "    num_samples_target = img_target_batch.shape[0]\n",
        "    assert num_samples == num_samples_target\n",
        "    for i in range(num_samples):\n",
        "        img_input_str = tf.io.serialize_tensor(img_input_batch[i, :, :, :])\n",
        "        img_target_str = tf.io.serialize_tensor(img_target_batch[i, :, :, :])\n",
        "        example = image_image_example(img_input_str, img_target_str)\n",
        "        writer.write(example.SerializeToString())\n",
        "\n",
        "def image_image_example(input_image_string, target_image_string):\n",
        "    feature = {\n",
        "          'input_image_raw': _bytes_feature(input_image_string),\n",
        "          'target_image_raw': _bytes_feature(target_image_string) \n",
        "    }\n",
        "    return tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "\n",
        "def _bytes_feature(value):\n",
        "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
        "  if isinstance(value, type(tf.constant(0))):\n",
        "    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
        "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "def split_data(filepath, proportion, irrelevant_characters):\n",
        "  files = glob.glob(filepath+'*')\n",
        "  random.shuffle(files)\n",
        "  images = [file[:-irrelevant_characters] for file in files]\n",
        "\n",
        "  counts = dict()\n",
        "  for i in images:\n",
        "    counts[i] = counts.get(i, 0) + 1\n",
        "\n",
        "  i = 0\n",
        "  train_data_paths = []\n",
        "  val_data_paths = []\n",
        "  test_data_paths = []\n",
        "\n",
        "  for key, value in counts.items():\n",
        "    if i < len(files)*sum(data_split[0:1]):\n",
        "      train_data_paths += glob.glob(key + '*')\n",
        "      i += value\n",
        "    elif i < len(files)*sum(data_split[0:2]):\n",
        "      val_data_paths += glob.glob(key + '*')\n",
        "      i += value\n",
        "    elif i < len(files)*sum(data_split[0:3]):\n",
        "      test_data_paths += glob.glob(key + '*')\n",
        "      i += value\n",
        "  \n",
        "  train_data_paths = [path.replace(filepath,'') for path in train_data_paths]\n",
        "  val_data_paths = [path.replace(filepath,'') for path in val_data_paths]\n",
        "  test_data_paths = [path.replace(filepath,'') for path in test_data_paths]\n",
        "\n",
        "  return train_data_paths, val_data_paths, test_data_paths"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generacja TFRecords"
      ],
      "metadata": {
        "id": "bOVCJWhpeipv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if generate_malignant:\n",
        "  path_base_input_train = malignant_data[:-1]\n",
        "  path_base_target_train = malignant_data[:-1]\n",
        "  train_files_mal, test_files_mal, _ = split_data(malignant_data, data_split, char_irrel)\n",
        "\n",
        "  train_dset_mal = image_image_feeder(path_base_input_train, path_base_target_train, train_files_mal, train_files_mal, from_disk=True, batch_size = batch_size,\n",
        "                                    standarize=False, invert_input=True, invert_target=True, patch_size=patch_size, num_patches_per_image=num_patches_per_image)\n",
        "  \n",
        "  \n",
        "  test_dset_mal = image_image_feeder(path_base_input_train, path_base_target_train, test_files_mal, test_files_mal, from_disk=True, batch_size = batch_size,\n",
        "                                    standarize=False, invert_input=True, invert_target=True, patch_size=patch_size, num_patches_per_image=num_patches_per_image)\n",
        "\n",
        "  img_img_dataset_2_tfrecord(train_dset_mal, tfrecord_path_train_mal, len(train_files_mal))\n",
        "  img_img_dataset_2_tfrecord(test_dset_mal, tfrecord_path_test_mal, len(test_files_mal))"
      ],
      "metadata": {
        "id": "HUhPqQczelPk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 659
        },
        "outputId": "8704126b-303a-41d3-e604-49d81988eb12"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotImplementedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-f3f7f2a052f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   train_dset_mal = image_image_feeder(path_base_input_train, path_base_target_train, train_files_mal, train_files_mal, from_disk=True, batch_size = batch_size,\n\u001b[0;32m----> 7\u001b[0;31m                                     standarize=False, invert_input=True, invert_target=True, patch_size=patch_size, num_patches_per_image=num_patches_per_image)\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-fc8492b0463f>\u001b[0m in \u001b[0;36mimage_image_feeder\u001b[0;34m(path_base_input, path_base_target, filenames_input, filenames_target, from_disk, num_patches_per_image, patch_size, shuffle_buffer_size_images, shuffle_buffer_size_patches, batch_size, intensity_thresh_input, intensity_thresh_target, accept_thresh_input, accept_thresh_target, invert_input, invert_target, max_tries, p_augment, augmentations, shuffle_images, shuffle_patches, standarize, num_prefetched_patches, num_parallel_calls)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfrom_disk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_paired_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstandarize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2014\u001b[0m         warnings.warn(\"The `deterministic` argument has no effect unless the \"\n\u001b[1;32m   2015\u001b[0m                       \"`num_parallel_calls` argument is specified.\")\n\u001b[0;32m-> 2016\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mMapDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2017\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2018\u001b[0m       return ParallelMapDataset(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m   5193\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5194\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5195\u001b[0;31m         use_legacy_function=use_legacy_function)\n\u001b[0m\u001b[1;32m   5196\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_metadata_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMetadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5197\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/structured_function.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mfn_factory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace_tf_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefun_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m     \u001b[0;31m# There is no graph to add in eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0madd_to_graph\u001b[0m \u001b[0;34m&=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3069\u001b[0m     \"\"\"\n\u001b[1;32m   3070\u001b[0m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0;32m-> 3071\u001b[0;31m         *args, **kwargs)\n\u001b[0m\u001b[1;32m   3072\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3073\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3034\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3035\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3036\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3037\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3038\u001b[0m       captured = object_identity.ObjectIdentitySet(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_call_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3292\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3293\u001b[0m           self._function_cache.add(cache_key, cache_key_deletion_observer,\n\u001b[1;32m   3294\u001b[0m                                    graph_function)\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3138\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3139\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3140\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3141\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3142\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1159\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/structured_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    246\u001b[0m           attributes=defun_kwargs)\n\u001b[1;32m    247\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/structured_function.py\u001b[0m in \u001b[0;36mwrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    175\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_should_unpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0m_should_pack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    690\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: in user code:\n\n    File \"<ipython-input-4-fc8492b0463f>\", line 219, in load_paired_images  *\n        image_decoded_input = tfio.experimental.image.decode_tiff(image_string_input)\n    File \"/usr/local/lib/python3.7/dist-packages/tensorflow_io/python/experimental/image_ops.py\", line 87, in decode_tiff  **\n        return core_ops.io_decode_tiff(contents, index, name=name)\n    File \"/usr/local/lib/python3.7/dist-packages/tensorflow_io/python/ops/__init__.py\", line 88, in __getattr__\n        return getattr(self._load(), attrb)\n    File \"/usr/local/lib/python3.7/dist-packages/tensorflow_io/python/ops/__init__.py\", line 84, in _load\n        self._mod = _load_library(self._library)\n    File \"/usr/local/lib/python3.7/dist-packages/tensorflow_io/python/ops/__init__.py\", line 71, in _load_library\n        + f\"{filename}, from paths: {filenames}\\ncaused by: {errs}\"\n\n    NotImplementedError: unable to open file: libtensorflow_io.so, from paths: ['/usr/local/lib/python3.7/dist-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n    caused by: ['/usr/local/lib/python3.7/dist-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZNK10tensorflow4data11DatasetBase8FinalizeEPNS_15OpKernelContextESt8functionIFNS_8StatusOrISt10unique_ptrIS1_NS_4core15RefCountDeleterEEEEvEE']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if generate_benign:\n",
        "  path_base_input_train = benign_data[:-1]\n",
        "  path_base_target_train = benign_data[:-1]\n",
        "  train_files_ben, test_files_ben, _ = split_data(benign_data, data_split, char_irrel)\n",
        "\n",
        "  train_dset_ben = image_image_feeder(path_base_input_train, path_base_target_train, train_files_ben, train_files_ben, from_disk=True, batch_size = batch_size,\n",
        "                                    standarize=False, invert_input=True, invert_target=True, patch_size=patch_size, num_patches_per_image=num_patches_per_image)\n",
        "  \n",
        "  test_dset_ben = image_image_feeder(path_base_input_train, path_base_target_train, test_files_ben, test_files_ben, from_disk=True, batch_size = batch_size,\n",
        "                                    standarize=False, invert_input=True, invert_target=True, patch_size=patch_size, num_patches_per_image=num_patches_per_image)\n",
        "\n",
        "  img_img_dataset_2_tfrecord(train_dset_ben, tfrecord_path_train_ben,  len(train_files_ben))\n",
        "  img_img_dataset_2_tfrecord(test_dset_ben, tfrecord_path_test_ben,  len(test_files_ben))"
      ],
      "metadata": {
        "id": "knt8M0o_euWq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}